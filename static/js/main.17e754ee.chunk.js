(this["webpackJsonpmvig-rhos-mainpage"]=this["webpackJsonpmvig-rhos-mainpage"]||[]).push([[0],{33:function(e,t,i){},48:function(e,t,i){"use strict";i.r(t);var n=i(1),s=i(23),c=i.n(s),r=(i(33),i(4)),a=i(5),o=i(6),l=i(7),j=i(24),h=i(27),b=i(3),d=i(8),u=i.n(d),p=i(0),O=function(e){Object(o.a)(i,e);var t=Object(l.a)(i);function i(){return Object(r.a)(this,i),t.apply(this,arguments)}return Object(a.a)(i,[{key:"render",value:function(){return Object(p.jsxs)("header",{id:"home",style:{backgroundImage:"url(../images/HAKE-A2V.gif)",backgroundRepeat:"no-repeat",backgroundSize:"100%"},children:[Object(p.jsxs)("nav",{id:"nav-wrap",children:[Object(p.jsx)("a",{className:"mobile-btn",href:"#nav-wrap",title:"Show navigation",children:"Show navigation"}),Object(p.jsx)("a",{className:"mobile-btn",href:"#home",title:"Hide navigation",children:"Hide navigation"}),Object(p.jsxs)("ul",{id:"nav",className:"nav",children:[Object(p.jsx)("li",{className:"current",children:Object(p.jsx)("a",{className:"smoothscroll",href:"#home",children:"Home"})}),Object(p.jsx)("li",{children:Object(p.jsx)("a",{className:"smoothscroll",href:"#about",children:"About"})}),Object(p.jsx)("li",{children:Object(p.jsx)("a",{className:"smoothscroll",href:"#news",children:"News"})}),Object(p.jsx)("li",{children:Object(p.jsx)("a",{className:"smoothscroll",href:"#projects",children:"Projects"})}),Object(p.jsx)("li",{children:Object(p.jsx)("a",{className:"smoothscroll",href:"#publications",children:"Publications"})}),Object(p.jsx)("li",{children:Object(p.jsx)("a",{className:"smoothscroll",href:"#people",children:"People"})})]})]}),Object(p.jsx)("div",{className:"row banner",children:Object(p.jsxs)("div",{className:"banner-text",children:[Object(p.jsx)(u.a,{bottom:!0,children:Object(p.jsx)("h1",{className:"responsive-headline",children:"RHOS"})}),Object(p.jsx)(u.a,{bottom:!0,duration:1200,children:Object(p.jsx)("h3",{children:"Robot \u2022 Human \u2022 Object \u2022 Scene"})}),Object(p.jsx)("hr",{}),Object(p.jsx)(u.a,{bottom:!0,duration:2e3,children:Object(p.jsxs)("ul",{className:"social",children:[Object(p.jsxs)("a",{href:"#projects",className:"button btn project-btn smoothscroll",children:[Object(p.jsx)("i",{className:"fa fa-book"}),"Projects"]}),Object(p.jsxs)("a",{href:"#recruit",className:"button btn github-btn smoothscroll",children:[Object(p.jsx)("i",{className:"fa fa-bookmark"}),"Recruitment"]})]})})]})}),Object(p.jsx)("p",{className:"scrolldown",children:Object(p.jsx)("a",{className:"smoothscroll",href:"#about",children:Object(p.jsx)("i",{className:"icon-down-circle"})})})]})}}]),i}(n.Component),m=O,x=function(e){Object(o.a)(i,e);var t=Object(l.a)(i);function i(){return Object(r.a)(this,i),t.apply(this,arguments)}return Object(a.a)(i,[{key:"render",value:function(){var e=function(e){return Object(p.jsx)("span",{style:{textDecoration:"line-through",textDecorationThickness:2},children:e.children})};return[Object(p.jsx)("section",{id:"about",children:Object(p.jsxs)("div",{className:"row",children:[Object(p.jsx)("div",{className:"three columns",children:Object(p.jsx)("h1",{children:Object(p.jsx)("span",{style:{color:"#fff"},children:"RHOS"})})}),Object(p.jsxs)("div",{className:"nine columns main-col",children:[Object(p.jsx)("h2",{children:"About"}),Object(p.jsxs)("div",{children:[Object(p.jsxs)("p",{children:["Hi, this is the website of RHOS at ",Object(p.jsx)("a",{href:"https://www.mvig.org/",children:"Machine Vision and Intelligence Group (MVIG)"}),". We study ",Object(p.jsx)("i",{children:Object(p.jsx)("b",{children:"Human Activity Understanding"})}),", ",Object(p.jsx)("i",{children:Object(p.jsx)("b",{children:"Visual Reasoning"})}),", and ",Object(p.jsx)("i",{children:Object(p.jsx)("b",{children:"Embodied AI"})}),". We are building a knowledge-driven system that enables intelligent agents to perceive human activities, reason human behavior logics, learn skills from human activities, and interact with environment."]}),Object(p.jsx)("p",{children:Object(p.jsx)("b",{children:"Research Interests: "})}),Object(p.jsxs)("p",{children:["(S) ",Object(p.jsx)("b",{children:"Embodied AI"}),": how to make agents learn skills from humans and interact with humans.",Object(p.jsx)("br",{}),"(S-1) ",Object(p.jsx)("b",{children:"Human Activity Understanding"}),": how to learn and ground complex/ambiguous human activity concepts (body motion, human-object/human/scene interaction) and object concepts from multi-modal information (2D-3D-4D).",Object(p.jsx)("br",{}),"(S-2) ",Object(p.jsx)("b",{children:"Visual Reasoning"}),": how to mine, capture, and embed the logics and causal relations from human activities.",Object(p.jsx)("br",{}),"(S-3) ",Object(p.jsx)("b",{children:"General Multi-Modal Foundation Models"}),": especially for human-centric perception tasks.",Object(p.jsx)("br",{}),"(S-4) ",Object(p.jsx)("b",{children:"Activity Understanding from A Cognitive Perspective"}),": work with multidisciplinary researchers to study how the brain perceives activities.",Object(p.jsx)("br",{}),"(E) ",Object(p.jsx)("b",{children:"Human-Robot Interaction for Smart Hospital"}),": work with the healthcare team (doctors and engineers) in SJTU to develop intelligent robots to help people."]})]}),Object(p.jsx)("div",{className:"row",children:Object(p.jsxs)("div",{className:"columns ",children:[Object(p.jsx)("h2",{children:"Contact Details"}),Object(p.jsxs)("p",{className:"address",children:[Object(p.jsx)("span",{children:"Yong-Lu Li"}),Object(p.jsx)("br",{}),Object(p.jsx)("span",{children:"Email: yonglu_li[at]sjtu[dot]edu[dot]cn"}),Object(p.jsx)("br",{}),Object(p.jsx)("span",{children:"Office: SEIEE-3-301"}),Object(p.jsx)("br",{}),Object(p.jsx)("span",{children:"Shanghai Jiao Tong University"}),Object(p.jsx)("br",{}),Object(p.jsxs)("a",{href:"https://dirtyharrylyl.github.io/",style:{marginRight:"10px"},children:[Object(p.jsx)("i",{className:"fa fa-bookmark"})," Personal Website"]}),Object(p.jsx)("br",{}),Object(p.jsxs)("a",{href:"https://scholar.google.com.hk/citations?user=UExAaVgAAAAJ",style:{marginRight:"10px"},children:[Object(p.jsx)("i",{className:"fa fa-bookmark"})," Google Scholar"]}),Object(p.jsxs)("a",{href:"https://github.com/DirtyHarryLYL",style:{marginRight:"10px"},children:[Object(p.jsx)("i",{className:"fa fa-github"})," Github"]}),Object(p.jsxs)("a",{href:"https://www.linkedin.com/in/%E6%B0%B8%E9%9C%B2-%E6%9D%8E-991b99139/",style:{marginRight:"10px"},children:[Object(p.jsx)("i",{className:"fa fa-bookmark"})," LinkedIn"]}),Object(p.jsxs)("a",{href:"https://dblp.org/pid/198/9345.html",style:{marginRight:"10px"},children:[Object(p.jsx)("i",{className:"fa fa-bookmark"})," dblp"]}),Object(p.jsxs)("a",{href:"https://www.semanticscholar.org/author/Yong-Lu-Li/10384643",style:{marginRight:"10px"},children:[Object(p.jsx)("i",{className:"fa fa-bookmark"})," Semantic Scholar"]})]})]})})]})]})},"about"),Object(p.jsx)("section",{id:"recruit",children:Object(p.jsx)("div",{id:"resume",children:Object(p.jsxs)("div",{className:"row work",children:[Object(p.jsx)("div",{className:"three columns header-col",children:Object(p.jsx)("h1",{children:Object(p.jsx)("span",{children:"Recruitment"})})}),Object(p.jsxs)("div",{className:"nine columns main-col date",children:[Object(p.jsx)("b",{children:"Recruitment"}),": We are actively looking for self-motivated ",Object(p.jsxs)("b",{children:["students (master/",Object(p.jsx)(e,{children:"PhD"}),", 2023 fall), interns/engineers/visitors"]})," (CV/ML/ROB/NLP background, always welcome) to join us in ",Object(p.jsx)("a",{href:"https://www.mvig.org/",style:{color:"red"},children:"Machine Vision and Intelligence Group (MVIG)"}),". If you share same/similar interests, feel free to drop me an email with your resume."]})]})})},"recruit")]}}]),i}(n.Component),g=x,f=function(e){Object(o.a)(i,e);var t=Object(l.a)(i);function i(){return Object(r.a)(this,i),t.apply(this,arguments)}return Object(a.a)(i,[{key:"render",value:function(){return Object(p.jsxs)("a",{href:"/hake",children:[Object(p.jsxs)("b",{children:[Object(p.jsx)("span",{style:{color:"red"},children:"H"}),Object(p.jsx)("span",{style:{color:"blue"},children:"A"}),Object(p.jsx)("span",{style:{color:"red"},children:"KE"})]}),this.props.children]})}}]),i}(n.Component),v=f,y=function(e){Object(o.a)(i,e);var t=Object(l.a)(i);function i(){return Object(r.a)(this,i),t.apply(this,arguments)}return Object(a.a)(i,[{key:"render",value:function(){var e=this.props.date,t=this.props.children;return Object(p.jsxs)("p",{className:"date",children:[Object(p.jsxs)("span",{children:["\u2022"," "]}),Object(p.jsxs)("b",{children:["[",e,"] "]}),t]})}}]),i}(n.Component),w=y,L=function(e){Object(o.a)(i,e);var t=Object(l.a)(i);function i(){return Object(r.a)(this,i),t.apply(this,arguments)}return Object(a.a)(i,[{key:"render",value:function(){return Object(p.jsx)("section",{id:"news",children:Object(p.jsx)("div",{id:"resume",children:Object(p.jsx)(u.a,{duration:1e3,children:Object(p.jsxs)("div",{className:"row work",children:[Object(p.jsx)("div",{className:"three columns header-col",children:Object(p.jsx)("h1",{children:Object(p.jsx)("span",{children:"News and Olds"})})}),Object(p.jsxs)("div",{className:"nine columns main-col date",children:[Object(p.jsxs)(w,{date:"2022.07",children:["Two papers on ",Object(p.jsx)("b",{children:"longtailed learning, HOI detection"})," are accepted by ECCV'22, arXivs and code are coming soon"]}),Object(p.jsxs)(w,{date:"2022.03",children:["Five papers on ",Object(p.jsx)("b",{children:"HOI detection/prediction, trajection prediction, 3D detection/keypoints"})," are accepted by CVPR'22, papers and code are coming soon"]}),Object(p.jsxs)(w,{date:"2022.02",children:["We release the human body part state labels based on AVA: ",Object(p.jsxs)("b",{children:[Object(p.jsx)("a",{href:"https://github.com/DirtyHarryLYL/HAKE-AVA",children:"HAKE-AVA"})," and ",Object(p.jsx)("a",{href:"https://arxiv.org/abs/2202.06851",children:"HAKE 2.0"})]})]}),Object(p.jsxs)(w,{date:"2021.12",children:["Our work on ",Object(p.jsx)("b",{children:"HOI generalization"})," will appear at AAAI'22"]}),Object(p.jsxs)(w,{date:"2021.10",children:["Yong-Lu recieves ",Object(p.jsx)("b",{children:"Outstanding Reviewer Award"})," from NeurIPS'21"]}),Object(p.jsxs)(w,{date:"2021.10",children:[Object(p.jsx)("b",{children:"Learning Single/Multi-Attribute of Object with Symmetry and Group"})," is accepted by TPAMI"]}),Object(p.jsxs)(w,{date:"2021.09",children:["Our work ",Object(p.jsx)("b",{children:"Localization with Sampling-Argmax"})," will appear at NeurIPS'21"]}),Object(p.jsxs)(w,{date:"2021.05",children:["Yong-Lu is selected as the ",Object(p.jsx)("b",{children:Object(p.jsx)("a",{href:"https://mp.weixin.qq.com/s/v7ITiZXOJiDUbPlRlcqQRA",children:"Chinese AI New Star Top-100 (Machine Learning)"})})]}),Object(p.jsxs)(w,{date:"2021.02",children:["Upgraded ",Object(p.jsx)("b",{children:Object(p.jsx)("a",{href:"https://github.com/DirtyHarryLYL/HAKE-Action-Torch/tree/Activity2Vec",children:"HAKE-Activity2Vec"})})," is released! Images/Videos --\x3e human box + ID + skeleton + part states + action + representation. ",Object(p.jsx)("a",{style:{textDecoration:"underline"},href:"https://youtu.be/ty-bXDInLMQ",children:"[Demo]"})," ",Object(p.jsx)("a",{style:{textDecoration:"underline"},href:"https://drive.google.com/file/d/1iZ57hKjus2lKbv1MAB-TLFrChSoWGD5e/view?usp=sharing",children:"[Description]"})]}),Object(p.jsxs)(w,{date:"2021.01",children:[Object(p.jsxs)("b",{children:[Object(p.jsx)("a",{href:"https://arxiv.org/abs/2101.10292",children:"TIN"})," (Transferable Interactiveness Network)"]})," is accepted by TPAMI"]}),Object(p.jsxs)(w,{date:"2021.01",children:["Recieved ",Object(p.jsx)("b",{children:Object(p.jsx)("a",{href:"http://scholarship.baidu.com/",children:"Baidu Scholarship"})})," (10 recipients globally)"]}),Object(p.jsxs)(w,{date:"2020.12",children:[Object(p.jsx)("b",{children:Object(p.jsx)("a",{style:{textDecoration:"underline"},href:"https://arxiv.org/abs/2010.01007",children:"DecAug"})})," is accepted by AAAI'21"]}),Object(p.jsxs)(w,{date:"2020.09",children:["Our work ",Object(p.jsx)("b",{children:"HOI Analysis"})," will appear at NeurIPS 2020"]}),Object(p.jsxs)(w,{date:"2020.07",children:["Yong-Lu recieves ",Object(p.jsx)("b",{children:Object(p.jsx)("a",{href:"https://www.thepaper.cn/newsDetail_forward_8240318",children:"WAIC YunFan Award"})})," and be among the 2nd A-Class Project"]}),Object(p.jsxs)(w,{date:"2020.06",children:["The larger ",Object(p.jsx)("b",{children:Object(p.jsx)("a",{href:"https://github.com/DirtyHarryLYL/HAKE#hake-large-for-instance-level-hoi-detection",children:"HAKE-Large"})})," (>120K images with activity and part state labels) is released"]}),Object(p.jsxs)(w,{date:"2020.02",children:["Three papers ",Object(p.jsx)("b",{children:"Image-based HAKE: PaSta-Net"}),", ",Object(p.jsx)("b",{children:"2D-3D Joint HOI Learning"}),", ",Object(p.jsx)("b",{children:"Symmetry-based Attribute-Object Learning"})," are accepted in ",Object(p.jsx)("a",{href:"http://cvpr2020.thecvf.com/",children:"CVPR'20"}),"! Papers and corresponding resources (code, data) will be released soon"]}),Object(p.jsxs)(w,{date:"2019.07",children:["Our paper ",Object(p.jsx)("b",{children:"InstaBoost"})," is accepted in ",Object(p.jsx)("a",{href:"http://iccv2019.thecvf.com/",children:"ICCV'19"})]}),Object(p.jsxs)(w,{date:"2019.06",children:["The Part I of our ",Object(p.jsx)(v,{}),": ",Object(p.jsx)("b",{children:Object(p.jsx)("a",{href:"http://hake-mvig.cn/download/",children:"HAKE-HICO"})})," which contains the image-level part-state annotations is released"]}),Object(p.jsxs)(w,{date:"2019.04",children:["Our project ",Object(p.jsx)(v,{})," (Human Activity Knowledge Engine) begins trial operation"]}),Object(p.jsxs)(w,{date:"2019.02",children:["Our paper on ",Object(p.jsx)("b",{children:Object(p.jsx)("a",{href:"https://arxiv.org/abs/1811.08264",children:"Interactiveness"})})," is accepted in ",Object(p.jsx)("a",{href:"http://cvpr2019.thecvf.com/",children:"CVPR'19"})]}),Object(p.jsxs)(w,{date:"2018.07",children:["Our paper on ",Object(p.jsx)("b",{children:Object(p.jsx)("a",{href:"https://arxiv.org/abs/1801.08839",children:"GAN & Annotation Generation"})})," is accepted in ",Object(p.jsx)("a",{href:"https://eccv2018.org/",children:"ECCV'18"})]}),Object(p.jsxs)(w,{date:"2018.05",children:["Presentation (Kaibot Team) in ",Object(p.jsx)("a",{href:"https://icra2018.org/tidy-up-my-room-challenge/",children:"TIDY UP MY ROOM CHALLENGE | ICRA'18"})]}),Object(p.jsxs)(w,{date:"2018.02",children:["Our paper on ",Object(p.jsx)("b",{children:Object(p.jsx)("a",{href:"http://ai.ucsd.edu/~haosu/papers/cvpr18_partstate.pdf",children:"Object Part States"})})," is accepted in ",Object(p.jsx)("a",{href:"http://cvpr2018.thecvf.com/program/main_conference",children:"CVPR'18"})]})]})]})})})})}}]),i}(n.Component),N=L,C=i(22),A=i.n(C),k=function(e){Object(o.a)(i,e);var t=Object(l.a)(i);function i(){return Object(r.a)(this,i),t.apply(this,arguments)}return Object(a.a)(i,[{key:"render",value:function(){var e=this.props.short,t=this.props.full,i=this.props.year,n=this.props.url,s=this.props.children;return Object(p.jsxs)("div",{children:[Object(p.jsxs)("a",{href:n,children:[Object(p.jsx)("h3",{style:{display:"inline"},children:e})," ",Object(p.jsx)("i",{className:"fa fa-external-link",style:{height:"0.5em",verticalAlign:"top"}})]}),Object(p.jsxs)("p",{className:"info",children:[t," ",Object(p.jsx)("span",{children:"\u2022"}),Object(p.jsx)("em",{className:"date",children:i})]}),Object(p.jsx)("p",{children:s})]},e)}}]),i}(n.Component),D=0,H=function(e){Object(o.a)(i,e);var t=Object(l.a)(i);function i(){return Object(r.a)(this,i),t.apply(this,arguments)}return Object(a.a)(i,[{key:"render",value:function(){var e,t=this.props.name,i="images/portfolio/"+this.props.image;return e=this.props.url?Object(p.jsx)("a",{href:this.props.url,children:t}):Object(p.jsx)("span",{children:t}),Object(p.jsx)("div",{className:"columns portfolio-item",children:Object(p.jsxs)("div",{className:"item-wrap",children:[Object(p.jsxs)("div",{id:"image-wrap",style:{position:"relative"},children:[Object(p.jsxs)("div",{style:{position:"absolute",width:"100%",height:"100%",objectFit:"cover",verticalAlign:"middle"},children:[Object(p.jsx)("span",{style:{display:"inline-block",height:"100%",verticalAlign:"middle"}}),Object(p.jsx)(A.a,{alt:"missing image",src:i,style:{verticalAlign:"middle"}})]}),Object(p.jsx)("div",{style:{paddingBottom:"100%"}})]}),Object(p.jsx)("div",{style:{textAlign:"center",backgroundColor:"#f8f8f8f8"},children:e})]})},D++)}}]),i}(n.Component),P=function(e){Object(o.a)(i,e);var t=Object(l.a)(i);function i(){return Object(r.a)(this,i),t.apply(this,arguments)}return Object(a.a)(i,[{key:"render",value:function(){return Object(p.jsxs)("section",{id:"projects",children:[Object(p.jsx)("div",{id:"resume",children:Object(p.jsx)(u.a,{left:!0,duration:1300,children:Object(p.jsxs)("div",{className:"row education",children:[Object(p.jsx)("div",{className:"three columns header-col",children:Object(p.jsx)("h1",{children:Object(p.jsx)("span",{children:"Projects"})})}),Object(p.jsx)("div",{className:"nine columns main-col",children:Object(p.jsx)("div",{className:"row item",children:Object(p.jsxs)("div",{className:"twelve columns",children:[Object(p.jsxs)(k,{year:"2017",short:"HAKE",full:"Human Activity Knowledge Engine",url:"/hake",children:["Human Activity Knowledge Engine (",Object(p.jsx)(v,{}),") is a knowledge-driven system that aims at enabling intelligent agents to perceive human activities, reason human behavior logics, learn skills from human activities, and interact with objects and environments."]}),Object(p.jsx)(k,{year:"2022",short:"OCL",full:"Object Concept Learning",url:"/ocl",children:"We propose a challenging Object Concept Learning (OCL) task to push the envelope of object understanding. It requires machines to reason out object affordances and simultaneously give the reason: what attributes make an object possesses these affordances."})]})})})]})})},"papers"),Object(p.jsx)("div",{id:"portfolio",children:Object(p.jsx)(u.a,{left:!0,duration:1e3,distance:"40px",children:Object(p.jsx)("div",{className:"row",children:Object(p.jsxs)("div",{className:"twelve columns collapsed",children:[Object(p.jsx)("h1",{children:"Check Out Some of Our Works."}),Object(p.jsxs)("div",{id:"portfolio-wrapper",className:"bgrid-quarters s-bgrid-thirds cf",children:[Object(p.jsx)(H,{name:Object(p.jsx)(v,{children:"2.0"}),image:"2022_hake2.0.jpg"}),Object(p.jsx)(H,{name:"PartMap",image:"2022_ECCV_partmap.jpg",url:"https://github.com/enlighten0707/Body-Part-Map-for-Interactiveness"}),Object(p.jsx)(H,{name:"DLSA",image:"2022_ECCV_longtail.jpg",url:"https://github.com/silicx/DLSA"}),Object(p.jsx)(H,{name:"Interactiveness-Field",image:"2022_CVPR_InteractivenessField.JPG",url:"https://github.com/Foruck/Interactiveness-Field"}),Object(p.jsx)(H,{name:"DCR",image:"2022_CVPR_anticipate.JPG",url:"https://github.com/AllenXuuu/DCR"}),Object(p.jsx)(H,{name:"OC-Immunity",image:"2022_AAAI_hoi.JPG",url:"https://github.com/Foruck/OC-Immunity"}),Object(p.jsx)(H,{name:"TIN & TIN++",image:"2021_TPAMI_TIN.PNG",url:"https://github.com/DirtyHarryLYL/Transferable-Interactiveness-Network"}),Object(p.jsx)(H,{name:"SymNet",image:"2021_TPAMI_SymNet.JPG",url:"https://github.com/DirtyHarryLYL/SymNet"}),Object(p.jsx)(H,{name:"HOI Analysis",image:"2020_NeurIPS_analysis.png",url:"https://github.com/DirtyHarryLYL/HAKE-Action-Torch/tree/IDN-(Integrating-Decomposing-Network)"}),Object(p.jsx)(H,{name:"PaStaNet",image:"2020_CVPR_pastanet.PNG",url:"https://github.com/DirtyHarryLYL/HAKE-Action"}),Object(p.jsx)(H,{name:"DJ-RN",image:"2020_CVPR_djrn.PNG",url:"https://github.com/DirtyHarryLYL/DJ-RN"}),Object(p.jsx)(H,{name:Object(p.jsx)(v,{children:"1.0"}),image:"2019_hake1.PNG",url:""})]})]})})})},"portfolio")]})}}]),i}(n.Component),S=P,I=i(28),Y=function(e){Object(o.a)(i,e);var t=Object(l.a)(i);function i(){return Object(r.a)(this,i),t.apply(this,arguments)}return Object(a.a)(i,[{key:"render",value:function(){return this.props.href?Object(p.jsx)(I.a,{href:this.props.href,"data-show-count":"true","aria-label":"Star buttons/github-buttons on GitHub",children:"Star"}):null}}]),i}(n.Component),R=Y,X=function(e){Object(o.a)(i,e);var t=Object(l.a)(i);function i(){return Object(r.a)(this,i),t.apply(this,arguments)}return Object(a.a)(i,[{key:"render",value:function(){var e=this.props.title,t=this.props.author,i=this.props.conf,n=this.props.shortname?Object(p.jsxs)("span",{children:[this.props.shortname," \u2022 "]}):Object(p.jsx)("span",{}),s=this.props.github?Object(p.jsx)(R,{href:this.props.github}):Object(p.jsx)("span",{}),c=Object.entries(this.props.links).map((function(e){return Object(p.jsxs)("span",{children:[Object(p.jsxs)("a",{href:e[1],style:{textDecoration:"underline"},children:["[",e[0],"]"]})," "]},e[0])})),r=this.props.children?Object(p.jsx)("div",{children:this.props.children}):Object(p.jsx)("span",{});return Object(p.jsxs)("div",{style:{marginBottom:"20px"},children:[Object(p.jsx)("h4",{children:e}),t,Object(p.jsx)("br",{}),Object(p.jsx)("b",{children:i})," \u2022 ",n," ",c," ",s,r]},e)}}]),i}(n.Component),T=function(e){Object(o.a)(i,e);var t=Object(l.a)(i);function i(){return Object(r.a)(this,i),t.apply(this,arguments)}return Object(a.a)(i,[{key:"render",value:function(){return Object(p.jsx)("section",{id:"publications",children:Object(p.jsx)("div",{id:"resume",children:Object(p.jsx)(u.a,{duration:1e3,children:Object(p.jsxs)("div",{className:"row work",children:[Object(p.jsx)("div",{className:"three columns header-col",children:Object(p.jsx)("h1",{children:Object(p.jsx)("span",{children:"Papers"})})}),Object(p.jsxs)("div",{className:"nine columns main-col",children:[Object(p.jsx)(X,{title:"HAKE: A Knowledge Engine Foundation for Human Activity Understanding",author:Object(p.jsx)("span",{children:"Yong-Lu Li, Xinpeng Liu, Xiaoqian Wu, Yizhuo Li, Zuoyu Qiu, Liang Xu, Yue Xu, Hao-Shu Fang, Cewu Lu"}),conf:"Preprint",shortname:Object(p.jsxs)("span",{children:[Object(p.jsx)(v,{}),"2.0"]}),links:{arXiv:"https://arxiv.org/abs/2202.06851",PDF:"https://arxiv.org/pdf/2202.06851.pdf",Project:"http://hake-mvig.cn",Press:"https://mp.weixin.qq.com/s/0KoPD7SAaaFKycmTUDBPOg"}}),Object(p.jsx)(X,{title:"HAKE: Human Activity Knowledge Engine",author:Object(p.jsx)("span",{children:"Yong-Lu Li, Liang Xu, Xinpeng Liu, Xijie Huang, Yue Xu, Mingyang Chen, Ze Ma, Shiyi Wang, Hao-Shu Fang, Cewu Lu"}),conf:"Tech Report",shortname:Object(p.jsxs)("span",{children:[Object(p.jsx)(v,{}),"1.0"]}),links:{arXiv:"https://arxiv.org/abs/1904.06539",PDF:"https://arxiv.org/pdf/1904.06539.pdf",Project:"http://hake-mvig.cn",Code:"https://github.com/DirtyHarryLYL/HAKE"},children:Object(p.jsx)("table",{children:Object(p.jsxs)("tbody",{children:[Object(p.jsxs)("tr",{children:[Object(p.jsx)("td",{children:"Main Repo: "}),Object(p.jsxs)("td",{children:["HAKE ",Object(p.jsx)(R,{href:"https://github.com/DirtyHarryLYL/HAKE"})]}),Object(p.jsx)("td",{})]}),Object(p.jsxs)("tr",{children:[Object(p.jsx)("td",{children:"Sub-repos: "}),Object(p.jsxs)("td",{children:["Torch ",Object(p.jsx)(R,{href:"https://github.com/DirtyHarryLYL/HAKE-Action-Torch"})]}),Object(p.jsxs)("td",{children:["TF ",Object(p.jsx)(R,{href:"https://github.com/DirtyHarryLYL/HAKE-Action"})]})]}),Object(p.jsxs)("tr",{children:[Object(p.jsx)("td",{}),Object(p.jsxs)("td",{children:["Halpe ",Object(p.jsx)(R,{href:"https://github.com/Fang-Haoshu//Halpe-FullBody"})]}),Object(p.jsxs)("td",{children:["HOI List ",Object(p.jsx)(R,{href:"https://github.com/DirtyHarryLYL/HOI-Learning-List"})]})]})]})})}),Object(p.jsx)(X,{title:"Constructing Balance from Imbalance for Long-tailed Image Recognition",author:Object(p.jsx)("span",{children:"Yue Xu*, Yong-Lu Li*, Jiefeng Li, Cewu Lu (*=equal contribution)"}),conf:"ECCV 2022",shortname:"DLSA",links:{arXiv:"https://arxiv.org/abs/2208.02567",PDF:"https://arxiv.org/pdf/2208.02567.pdf",Code:"https://github.com/silicx/DLSA"},github:"https://github.com/silicx/DLSA"}),Object(p.jsx)(X,{title:"Mining Cross-Person Cues for Body-Part Interactiveness Learning in HOI Detection",author:Object(p.jsx)("span",{children:"Xiaoqian Wu*, Yong-Lu Li*, Xinpeng Liu, Junyi Zhang, Yuzhe Wu, Cewu Lu (*=equal contribution)"}),conf:"ECCV 2022",links:{arXiv:"https://arxiv.org/abs/2207.14192",PDF:"https://arxiv.org/pdf/2207.14192v1.pdf",Code:"https://github.com/enlighten0707/Body-Part-Map-for-Interactiveness"},github:"https://github.com/enlighten0707/Body-Part-Map-for-Interactiveness"}),Object(p.jsx)(X,{title:"Interactiveness Field of Human-Object Interactions",author:Object(p.jsx)("span",{children:"Xinpeng Liu*, Yong-Lu Li*, Xiaoqian Wu, Yu-Wing Tai, Cewu Lu, Chi Keung Tang (*=equal contribution)"}),conf:"CVPR 2022",links:{arXiv:"https://arxiv.org/abs/2204.07718",PDF:"https://arxiv.org/pdf/2204.07718.pdf",Code:"https://github.com/Foruck/Interactiveness-Field"},github:"https://github.com/Foruck/Interactiveness-Field"}),Object(p.jsx)(X,{title:"Human Trajectory Prediction with Momentary Observation",author:Object(p.jsx)("span",{children:"Jianhua Sun, Yuxuan Li, Liang Chai, Hao-Shu Fang, Yong-Lu Li, Cewu Lu"}),conf:"CVPR 2022",links:{PDF:"https://openaccess.thecvf.com/content/CVPR2022/papers/Sun_Human_Trajectory_Prediction_With_Momentary_Observation_CVPR_2022_paper.pdf"}}),Object(p.jsx)(X,{title:"Learn to Anticipate Future with Dynamic Context Removal",author:Object(p.jsx)("span",{children:"Xinyu Xu, Yong-Lu Li, Cewu Lu"}),conf:"CVPR 2022",shortname:"DCR",links:{arXiv:"https://arxiv.org/abs/2204.02587",PDF:"https://arxiv.org/pdf/2204.02587.pdf",Code:"https://github.com/AllenXuuu/DCR"},github:"https://github.com/AllenXuuu/DCR"}),Object(p.jsx)(X,{title:"Canonical Voting: Towards Robust Oriented Bounding Box Detection in 3D Scenes",author:Object(p.jsx)("span",{children:"Yang You, Zelin Ye, Yujing Lou, Chengkun Li, Yong-Lu Li, Lizhuang Ma, Weiming Wang, Cewu Lu"}),conf:"CVPR 2022",links:{arXiv:"https://arxiv.org/abs/2011.12001",PDF:"https://arxiv.org/pdf/2011.12001.pdf",Code:"https://github.com/qq456cvb/CanonicalVoting"},github:"https://github.com/qq456cvb/CanonicalVoting"}),Object(p.jsx)(X,{title:"UKPGAN: Unsupervised KeyPoint GANeration",author:Object(p.jsx)("span",{children:"Yang You, Wenhai Liu, Yong-Lu Li, Weiming Wang, Cewu Lu"}),conf:"CVPR 2022",links:{arXiv:"https://arxiv.org/abs/2011.11974",PDF:"https://arxiv.org/pdf/2011.11974.pdf",Code:"https://github.com/qq456cvb/UKPGAN"},github:"https://github.com/qq456cvb/UKPGAN"}),Object(p.jsx)(X,{title:"Highlighting Object Category Immunity for the Generalization of Human-Object Interaction Detection",author:Object(p.jsx)("span",{children:"Xinpeng Liu*, Yong-Lu Li*, Cewu Lu (*=equal contribution)"}),conf:"AAAI 2022",links:{arXiv:"https://arxiv.org/abs/2202.09492",PDF:"https://arxiv.org/pdf/2202.09492.pdf",Code:"https://github.com/Foruck/OC-Immunity"},github:"https://github.com/Foruck/OC-Immunity"}),Object(p.jsx)(X,{title:"Learning Single/Multi-Attribute of Object with Symmetry and Group",author:Object(p.jsx)("span",{children:"Yong-Lu Li, Yue Xu, Xinyu Xu, Xiaohan Mao, Cewu Lu"}),conf:"TPAMI 2021",shortname:"SymNet",links:{arXiv:"https://arxiv.org/abs/2110.04603",PDF:"https://arxiv.org/pdf/2110.04603.pdf",Code:"https://github.com/DirtyHarryLYL/SymNet"},github:"https://github.com/DirtyHarryLYL/SymNet",children:"An extension of our CVPR 2020 work (Symmetry and Group in Attribute-Object Compositions, SymNet)."}),Object(p.jsx)(X,{title:"Localization with Sampling-Argmax",author:Object(p.jsx)("span",{children:"Jiefeng Li, Tong Chen, Ruiqi Shi, Yujing Lou, Yong-Lu Li, Cewu Lu"}),conf:"NeurIPS 2021",links:{arXiv:"https://arxiv.org/abs/2110.08825",PDF:"https://arxiv.org/pdf/2110.08825.pdf",Code:"https://github.com/Jeff-sjtu/sampling-argmax"},github:"https://github.com/Jeff-sjtu/sampling-argmax"}),Object(p.jsx)(X,{title:"Transferable Interactiveness Knowledge for Human-Object Interaction Detection",author:Object(p.jsx)("span",{children:"Yong-Lu Li, Xinpeng Liu, Xiaoqian Wu, Xijie Huang, Liang Xu, Cewu Lu"}),conf:"TPAMI 2021",shortname:"TIN",links:{arXiv:"https://arxiv.org/abs/2101.10292",PDF:"https://arxiv.org/pdf/2101.10292.pdf",Code:"https://github.com/DirtyHarryLYL/Transferable-Interactiveness-Network"},github:"https://github.com/DirtyHarryLYL/Transferable-Interactiveness-Network",children:Object(p.jsx)("div",{children:"An extension of our CVPR 2019 work (Transferable Interactiveness Network, TIN)."})}),Object(p.jsx)(X,{title:"DecAug: Augmenting HOI Detection via Decomposition",author:Object(p.jsx)("span",{children:"Yichen Xie, Hao-Shu Fang, Dian Shao, Yong-Lu Li, Cewu Lu"}),conf:"AAAI 2021",links:{arXiv:"https://arxiv.org/abs/2010.01007",PDF:"https://arxiv.org/pdf/2010.01007.pdf"}}),Object(p.jsx)(X,{title:"HOI Analysis: Integrating and Decomposing Human-Object Interaction",author:Object(p.jsx)("span",{children:"Yong-Lu Li*, Xinpeng Liu*, Xiaoqian Wu, Yizhuo Li, Cewu Lu (*=equal contribution)"}),conf:"NeurIPS 2020",links:{arXiv:"https://arxiv.org/abs/2010.16219",PDF:"https://arxiv.org/pdf/2010.16219.pdf",Code:"https://github.com/DirtyHarryLYL/HAKE-Action-Torch/tree/IDN-(Integrating-Decomposing-Network)","Project: HAKE-Action-Torch":"https://github.com/DirtyHarryLYL/HAKE-Action-Torch/tree/master"},github:"https://github.com/DirtyHarryLYL/HAKE-Action-Torch/tree/IDN-(Integrating-Decomposing-Network)"}),Object(p.jsxs)(X,{title:"PaStaNet: Toward Human Activity Knowledge Engine",author:Object(p.jsx)("span",{children:"Yong-Lu Li, Liang Xu, Xinpeng Liu, Xijie Huang, Yue Xu, Shiyi Wang, Hao-Shu Fang, Ze Ma, Mingyang Chen, Cewu Lu. "}),conf:"CVPR 2020",links:{arXiv:"https://arxiv.org/abs/2004.00945",PDF:"https://arxiv.org/pdf/2004.00945.pdf",Video:"https://drive.google.com/file/d/16PCCK_flK2qW4QJVWoYXQwG3wgXd6yvT/view?usp=sharing",Slides:"https://drive.google.com/file/d/19J9uz3epBo3o9CIU85mzgLblRVNawl87/view?usp=sharing",Data:"https://github.com/DirtyHarryLYL/HAKE",Code:"https://github.com/DirtyHarryLYL/HAKE-Action"},github:"https://github.com/DirtyHarryLYL/HAKE-Action",children:[Object(p.jsx)("span",{style:{color:"red"},children:Object(p.jsx)("b",{children:"Oral Talk:"})})," ",Object(p.jsx)("a",{href:"http://ai.stanford.edu/~jingweij/cicv/#schedule",children:"Compositionality in Computer Vision"})," in CVPR 2020"]}),Object(p.jsx)(X,{title:"Detailed 2D-3D Joint Representation for Human-Object Interaction",author:Object(p.jsx)("span",{children:"Yong-Lu Li, Xinpeng Liu, Han Lu, Shiyi Wang, Junqi Liu, Jiefeng Li, Cewu Lu"}),conf:"CVPR 2020",shortname:"DJ-RN",links:{arXiv:"https://arxiv.org/abs/2004.08154",PDF:"https://arxiv.org/pdf/2004.08154.pdf",Video:"https://drive.google.com/file/d/14dK1tBLe3xHXyO_5WsRO2JcjJ95meaDB/view?usp=sharing",Slides:"https://drive.google.com/file/d/1A5bQZFsBOahj7dJgSnWR7jdyvMG58NkT/view?usp=sharing","Benchmark: Ambiguous-HOI":"https://github.com/DirtyHarryLYL/DJ-RN#ambiguous-hoi",Code:"https://github.com/DirtyHarryLYL/DJ-RN"},github:"https://github.com/DirtyHarryLYL/DJ-RN"}),Object(p.jsx)(X,{title:"Symmetry and Group in Attribute-Object Compositions",author:Object(p.jsx)("span",{children:"Yong-Lu Li, Yue Xu, Xiaohan Mao, Cewu Lu"}),conf:"CVPR 2020",shortname:"SymNet",links:{arXiv:"https://arxiv.org/abs/2004.00587",PDF:"https://arxiv.org/pdf/2004.00587.pdf",Video:"https://drive.google.com/file/d/1ZTSB2lJbDTH7D-7GdEJQGmszvEc2Vuwd/view?usp=sharing",Slides:"https://drive.google.com/file/d/1aqYeSIQkoTp1hYOJokDgoucdZcufN2iG/view?usp=sharing",Code:"https://github.com/DirtyHarryLYL/SymNet"},github:"https://github.com/DirtyHarryLYL/SymNet"}),Object(p.jsx)(X,{title:"InstaBoost: Boosting Instance Segmentation Via Probability Map Guided Copy-Pasting",author:Object(p.jsx)("span",{children:"Hao-Shu Fang*, Jianhua Sun*, Runzhong Wang*, Minghao Gou, Yong-Lu Li, Cewu Lu (*=equal contribution)"}),conf:"ICCV 2019",links:{arXiv:"https://arxiv.org/abs/1908.07801",PDF:"https://arxiv.org/pdf/1908.07801.pdf",Code:"https://github.com/GothicAi/Instaboost"},github:"https://github.com/GothicAi/Instaboost"}),Object(p.jsx)(X,{title:"Transferable Interactiveness Knowledge for Human-Object Interaction Detection",author:Object(p.jsx)("span",{children:"Yong-Lu Li, Siyuan Zhou, Xijie Huang, Liang Xu, Ze Ma, Hao-Shu Fang, Yan-Feng Wang, Cewu Lu"}),conf:"CVPR 2019",shortname:"TIN",links:{arXiv:"https://arxiv.org/abs/1811.08264",PDF:"https://arxiv.org/pdf/1811.08264.pdf",Code:"https://github.com/DirtyHarryLYL/Transferable-Interactiveness-Network"},github:"https://github.com/DirtyHarryLYL/Transferable-Interactiveness-Network"}),Object(p.jsx)(X,{title:"SRDA: Generating Instance Segmentation Annotation via Scanning, Reasoning and Domain Adaptation",author:Object(p.jsx)("span",{children:"Wenqiang Xu*, Yong-Lu Li*, Cewu Lu (*=equal contribution)"}),conf:"ECCV 2018",links:{arXiv:"https://arxiv.org/abs/1801.08839",PDF:"https://arxiv.org/pdf/1801.08839.pdf","Dataset (Instance-60k & 3D Object Models)":"https://drive.google.com/drive/folders/1t941oiLk40XQX2Q9a2HPmiDRUpiwazJO?usp=sharing",Code:"https://github.com/DirtyHarryLYL/SRDA-ECCV2018"},github:"https://github.com/DirtyHarryLYL/SRDA-ECCV2018"}),Object(p.jsx)(X,{title:"Beyond Holistic Object Recognition: Enriching Image Understanding with Part States",author:Object(p.jsx)("span",{children:"Cewu Lu, Hao Su, Yong-Lu Li, Yongyi Lu, Li Yi, Chi-Keung Tang, Leonidas J. Guibas"}),conf:"CVPR 2018",links:{PDF:"http://ai.ucsd.edu/~haosu/papers/cvpr18_partstate.pdf"}}),Object(p.jsx)(X,{title:"Optimization of Radial Distortion Self-Calibration for Structure from Motion from Uncalibrated UAV Images",author:Object(p.jsx)("span",{children:"Yong-Lu Li, Yinghao Cai, Dayong Wen, Yiping Yang"}),conf:"ICPR 2016",links:{PDF:"https://projet.liris.cnrs.fr/imagine/pub/proceedings/ICPR-2016/media/files/1010.pdf"}})]})]})})},"papers")})}}]),i}(n.Component),E=T,F=0,V=function(e){Object(o.a)(i,e);var t=Object(l.a)(i);function i(){return Object(r.a)(this,i),t.apply(this,arguments)}return Object(a.a)(i,[{key:"render",value:function(){var e,t,i=this.props.name,n=this.props.position,s=i.replace(" ","_");return e=this.props.altimage?"images/people/"+this.props.altimage:"images/people/"+s+".jpg",t=this.props.url?Object(p.jsx)("div",{children:Object(p.jsx)("a",{href:this.props.url,children:i})}):Object(p.jsx)("div",{children:i}),Object(p.jsx)("div",{className:"columns portfolio-item",children:Object(p.jsxs)("div",{className:"item-wrap",children:[Object(p.jsxs)("div",{id:"image-wrap",style:{position:"relative"},children:[Object(p.jsxs)("div",{style:{position:"absolute",width:"100%",height:"100%",objectFit:"cover",verticalAlign:"middle"},children:[Object(p.jsx)("span",{style:{display:"inline-block",height:"100%",verticalAlign:"middle"}}),Object(p.jsx)(A.a,{alt:"missing image",src:e,style:{verticalAlign:"middle"}})]}),Object(p.jsx)("div",{style:{paddingBottom:"150%"}})]}),Object(p.jsxs)("div",{style:{textAlign:"center",backgroundColor:"#f8f8f8f8"},children:[t,n]})]})},F++)}}]),i}(n.Component),K=function(e){Object(o.a)(i,e);var t=Object(l.a)(i);function i(){return Object(r.a)(this,i),t.apply(this,arguments)}return Object(a.a)(i,[{key:"render",value:function(){var e=this.props.name,t=e.replace(" ","_"),i=this.props.position;return this.props.url?Object(p.jsxs)("div",{children:[Object(p.jsx)("a",{href:this.props.url,children:e}),": ",i]},t):Object(p.jsxs)("div",{children:[Object(p.jsx)("span",{children:e}),": ",i]},t)}}]),i}(n.Component),M=function(e){Object(o.a)(i,e);var t=Object(l.a)(i);function i(){return Object(r.a)(this,i),t.apply(this,arguments)}return Object(a.a)(i,[{key:"render",value:function(){return Object(p.jsx)("section",{id:"people",children:Object(p.jsx)("div",{id:"portfolio",children:Object(p.jsx)(u.a,{left:!0,duration:1300,children:Object(p.jsxs)("div",{className:"row",children:[Object(p.jsx)("div",{className:"three columns header-col",children:Object(p.jsx)("h1",{children:Object(p.jsx)("span",{children:"People"})})}),Object(p.jsx)("div",{className:"nine columns collapsed",children:Object(p.jsxs)("div",{id:"portfolio-wrapper",className:"bgrid-quarters s-bgrid-thirds cf",children:[Object(p.jsx)(V,{name:"Cewu Lu",position:"Professor",url:"https://www.mvig.org/"}),Object(p.jsx)(V,{name:"Yong-Lu Li",position:"Assistant Professor",url:"https://dirtyharrylyl.github.io/"}),Object(p.jsx)(V,{name:"Jingru Tan",position:"Postdoc",altimage:"placeholder.png",url:"https://scholar.google.com/citations?user=l18d7kcAAAAJ"}),Object(p.jsx)(V,{name:"Xinpeng Liu",position:"PhD. Student",url:"https://foruck.github.io/"}),Object(p.jsx)(V,{name:"Yue Xu",position:"PhD. Student",url:"https://silicx.github.io/"}),Object(p.jsx)(V,{name:"Xiaoqian Wu",position:"PhD. Student",url:"https://scholar.google.com/citations?user=-PHR96oAAAAJ"}),Object(p.jsx)(V,{name:"Xiaohan Mao",position:"PhD. Student",url:"https://scholar.google.com/citations?user=-zT1NKwAAAAJ"}),Object(p.jsx)(V,{name:"Siqi Liu",position:"PhD. Student",altimage:"placeholder.png"}),Object(p.jsx)(V,{name:"Xinyu Xu",position:"Master Student",url:"https://xuxinyu.website"}),Object(p.jsx)(V,{name:"Junyi Zhang",position:"Undergraduate",url:"https://scholar.google.com/citations?user=LTi1tYsAAAAJ"}),Object(p.jsx)(V,{name:"Yiming Dou",position:"Undergraduate",url:"https://dou-yiming.github.io/"}),Object(p.jsx)(V,{name:"Zhemin Huang",position:"Undergraduate",altimage:"placeholder.png"}),Object(p.jsx)(V,{name:"Kaitong Cui",position:"Undergraduate",altimage:"placeholder.png"}),Object(p.jsx)(V,{name:"Yixing Li",position:"Undergraduate",url:"https://github.com/HEYyox/"}),Object(p.jsx)(V,{name:"Yikun Ji",position:"Undergraduate",url:"http://github.com/Gennadiyev/"}),Object(p.jsx)(V,{name:"Yuzhe Wu",position:"Undergraduate",altimage:"placeholder.png"})]})}),Object(p.jsx)("div",{className:"three columns header-col",children:Object(p.jsx)("h1",{children:Object(p.jsx)("span",{children:"Alumni"})})}),Object(p.jsx)("div",{className:"nine columns collapsed",children:Object(p.jsxs)("div",{id:"portfolio-wrapper",className:"bgrid-quarters s-bgrid-thirds cf",children:[Object(p.jsx)(K,{name:"Shaopeng Guo",position:"UCSD PhD",url:"https://coeusguo.github.io/"}),Object(p.jsx)(K,{name:"Xudong Lu",position:"CUHK, PhD"}),Object(p.jsx)(K,{name:"Hongwei Fan",position:"Sensetime"}),Object(p.jsx)(K,{name:"Yuan Yao",position:""}),Object(p.jsx)(K,{name:"Zuoyu Qiu",position:"SJTU"}),Object(p.jsx)(K,{name:"Junqi Liu",position:""}),Object(p.jsx)(K,{name:"Han Lu",position:"SJTU, PhD"}),Object(p.jsx)(K,{name:"Shiyi Wang",position:""}),Object(p.jsx)(K,{name:"Zhanke Zhou",position:""}),Object(p.jsx)(K,{name:"Mingyang Chen",position:""}),Object(p.jsx)(K,{name:"Siyuan Zhou",position:"SJTU"}),Object(p.jsx)(K,{name:"Liang Xu",position:"SJTU & EIAS, PhD",url:"https://liangxuy.github.io/"}),Object(p.jsx)(K,{name:"Ze Ma",position:"Columbia University, MSCS",url:"https://maqingyang.github.io/"}),Object(p.jsx)(K,{name:"Xijie Huang",url:"https://huangowen.github.io/",position:"HKUST, PhD"})]})})]})})},"portfolio")})}}]),i}(n.Component),J=M,G=function(e){Object(o.a)(i,e);var t=Object(l.a)(i);function i(){return Object(r.a)(this,i),t.apply(this,arguments)}return Object(a.a)(i,[{key:"render",value:function(){var e=[{name:"github",url:"https://github.com/MVIG-RHOS",className:"fa fa-github"}].map((function(e){return Object(p.jsx)("li",{children:Object(p.jsx)("a",{href:e.url,children:Object(p.jsx)("i",{className:e.className})})},e.name)}));return Object(p.jsx)("footer",{children:Object(p.jsxs)("div",{className:"row",children:[Object(p.jsx)(u.a,{bottom:!0,children:Object(p.jsxs)("div",{className:"twelve columns",children:[Object(p.jsx)("ul",{className:"social-links",children:e}),Object(p.jsxs)("ul",{className:"copyright",children:[Object(p.jsx)("li",{children:"\xa9 Copyright 2022 MVIG-RHOS"}),Object(p.jsxs)("li",{children:["Based on "," ",Object(p.jsx)("a",{title:"Styleshout",href:"http://www.styleshout.com/",children:"Styleshout"})]})]})]})}),Object(p.jsx)("div",{id:"go-top",children:Object(p.jsx)("a",{className:"smoothscroll",title:"Back to Top",href:"#home",children:Object(p.jsx)("i",{className:"icon-up-open"})})})]})})}}]),i}(n.Component),_=G,q=function(e){Object(o.a)(i,e);var t=Object(l.a)(i);function i(){return Object(r.a)(this,i),t.apply(this,arguments)}return Object(a.a)(i,[{key:"render",value:function(){return Object(p.jsxs)("div",{className:"Home",children:[Object(p.jsx)(m,{}),Object(p.jsx)(g,{}),Object(p.jsx)(N,{}),Object(p.jsx)(S,{}),Object(p.jsx)(E,{}),Object(p.jsx)(J,{}),Object(p.jsx)(_,{})]})}}]),i}(n.Component),U=q,W=function(e){Object(o.a)(i,e);var t=Object(l.a)(i);function i(){return Object(r.a)(this,i),t.apply(this,arguments)}return Object(a.a)(i,[{key:"render",value:function(){return window.location.replace("http://hake-mvig.cn/home"),Object(p.jsx)("div",{})}}]),i}(n.Component),B=W,z=function(e){Object(o.a)(i,e);var t=Object(l.a)(i);function i(){return Object(r.a)(this,i),t.apply(this,arguments)}return Object(a.a)(i,[{key:"render",value:function(){return Object(p.jsxs)("header",{id:"home",style:{backgroundColor:"#666",backgroundRepeat:"no-repeat",backgroundSize:"100%"},children:[Object(p.jsxs)("nav",{id:"nav-wrap",children:[Object(p.jsx)("a",{className:"mobile-btn",href:"#nav-wrap",title:"Show navigation",children:"Show navigation"}),Object(p.jsx)("a",{className:"mobile-btn",href:"#home",title:"Hide navigation",children:"Hide navigation"}),Object(p.jsxs)("ul",{id:"nav",className:"nav",children:[Object(p.jsx)("li",{children:Object(p.jsx)("a",{href:"/",children:"Home"})}),Object(p.jsx)("li",{className:"current",children:Object(p.jsx)("a",{href:"/ocl",children:"OCL"})}),Object(p.jsx)("li",{children:Object(p.jsx)("a",{className:"smoothscroll",href:"#demo",children:"Demo"})}),Object(p.jsx)("li",{children:Object(p.jsx)("a",{className:"smoothscroll",href:"#news",children:"News"})}),Object(p.jsx)("li",{children:Object(p.jsx)("a",{className:"smoothscroll",href:"#resources",children:"Resources"})})]})]}),Object(p.jsx)("div",{className:"row banner",children:Object(p.jsxs)("div",{className:"banner-text",children:[Object(p.jsx)(u.a,{bottom:!0,children:Object(p.jsx)("h1",{className:"responsive-headline",children:"OCL"})}),Object(p.jsx)(u.a,{bottom:!0,duration:1200,children:Object(p.jsx)("h3",{children:"Object Concept Learning"})}),Object(p.jsx)("hr",{}),Object(p.jsx)(u.a,{bottom:!0,duration:2e3,children:Object(p.jsxs)("ul",{className:"social",children:[Object(p.jsxs)("a",{href:"#about",className:"button btn project-btn smoothscroll",children:[Object(p.jsx)("i",{className:"fa fa-book"}),"ABout"]}),Object(p.jsxs)("a",{href:"./recruit",className:"button btn github-btn",children:[Object(p.jsx)("i",{className:"fa fa-github"}),"Github"]})]})})]})}),Object(p.jsx)("p",{className:"scrolldown",children:Object(p.jsx)("a",{className:"smoothscroll",href:"#about",children:Object(p.jsx)("i",{className:"icon-down-circle"})})})]})}}]),i}(n.Component),Z=z,Q=function(e){Object(o.a)(i,e);var t=Object(l.a)(i);function i(){return Object(r.a)(this,i),t.apply(this,arguments)}return Object(a.a)(i,[{key:"render",value:function(){return Object(p.jsx)("section",{id:"about",children:Object(p.jsx)(u.a,{duration:1e3,children:Object(p.jsx)("div",{className:"row",children:Object(p.jsxs)("div",{className:"twelve columns main-col",children:[Object(p.jsx)("h2",{children:"About"}),Object(p.jsx)("p",{children:"Understanding objects is a central building block of artificial intelligence, especially for embodied AI. Even though object recognition excels with deep learning, current machines still struggle to learn higher-level knowledge, e.g., what attributes does an object have, what can we do with an object. In this work, we propose a challenging Object Concept Learning (OCL) task to push the envelope of object understanding. It requires machines to reason out object affordances and simultaneously give the reason: what attributes make an object possesses these affordances. To support OCL, we build a densely annotated knowledge base including extensive labels for three levels of object concept: categories, attributes, and affordances, together with their causal relations. By analyzing the causal structure of OCL, we present a strong baseline, Object Concept Reasoning Network (OCRN). It leverages causal intervention and concept instantiation to infer the three levels following their causal relations."})]})})})})}}]),i}(n.Component),$=Q,ee=function(e){Object(o.a)(i,e);var t=Object(l.a)(i);function i(){return Object(r.a)(this,i),t.apply(this,arguments)}return Object(a.a)(i,[{key:"render",value:function(){return Object(p.jsx)("section",{id:"demo",children:Object(p.jsx)("div",{id:"resume",children:Object(p.jsx)(u.a,{left:!0,duration:1300,children:Object(p.jsxs)("div",{className:"row work",children:[Object(p.jsx)("div",{className:"three columns header-col",children:Object(p.jsx)("h1",{children:Object(p.jsx)("span",{children:"Demo"})})}),Object(p.jsxs)("div",{className:"nine columns main-col date",children:[Object(p.jsx)("iframe",{title:"OCL Demo",width:"750",height:"430",src:"https://www.youtube.com/embed/dQw4w9WgXcQ",frameborder:"0",allow:"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture",allowfullscreen:""}),Object(p.jsxs)("div",{style:{fontSize:"18px",marginTop:"10px"},children:[Object(p.jsxs)("b",{children:["OCL: ",Object(p.jsx)("a",{href:"https://github.com/DirtyHarryLYL/Object_Concept_Learning",children:"[Code]"})]}),", ",Object(p.jsx)("b",{children:Object(p.jsxs)("a",{style:{textDecoration:"underline"},href:"https://youtu.be/",children:["[",Object(p.jsx)("span",{style:{color:"red"},children:"YouTube"}),"]"]})})," ",Object(p.jsx)("b",{children:Object(p.jsxs)("a",{style:{textDecoration:"underline"},href:"https://www.bilibili.com/video/",children:["[",Object(p.jsx)("span",{style:{color:"red"},children:"bilibili"}),"]"]})})]}),Object(p.jsx)("div",{style:{fontSize:"18px",marginTop:"10px"},children:"Pipeline: Category --\x3e Category attribute + affordance; Images --\x3e object box + instance attribute + instance affordance + causal reasoning rules"})]})]})})})})}}]),i}(n.Component),te=ee,ie=function(e){Object(o.a)(i,e);var t=Object(l.a)(i);function i(){return Object(r.a)(this,i),t.apply(this,arguments)}return Object(a.a)(i,[{key:"render",value:function(){return Object(p.jsx)("section",{id:"news",children:Object(p.jsx)("div",{id:"resume",children:Object(p.jsx)(u.a,{left:!0,duration:1300,children:Object(p.jsxs)("div",{className:"row work",children:[Object(p.jsx)("div",{className:"three columns header-col",children:Object(p.jsx)("h1",{children:Object(p.jsx)("span",{children:"News"})})}),Object(p.jsx)("div",{className:"nine columns main-col date",children:Object(p.jsx)(w,{date:"2022.09",children:"OCL is on trial running."})})]})})})})}}]),i}(n.Component),ne=ie,se=function(e){Object(o.a)(i,e);var t=Object(l.a)(i);function i(){return Object(r.a)(this,i),t.apply(this,arguments)}return Object(a.a)(i,[{key:"render",value:function(){return Object(p.jsx)("section",{id:"news",children:Object(p.jsx)("div",{id:"resume",children:Object(p.jsx)(u.a,{left:!0,duration:1300,children:Object(p.jsxs)("div",{className:"row work",children:[Object(p.jsx)("div",{className:"three columns header-col",children:Object(p.jsx)("h1",{children:Object(p.jsx)("span",{children:"Resources"})})}),Object(p.jsxs)("div",{className:"nine columns main-col date",children:[Object(p.jsxs)("div",{children:[Object(p.jsx)("h4",{children:"OCL data"}),Object(p.jsx)("a",{href:"/",children:"Download link"}),Object(p.jsx)("a",{href:"/",children:"Licence"})]}),Object(p.jsxs)("div",{children:[Object(p.jsx)("h4",{children:"Tech report"}),Object(p.jsx)("a",{href:"/",children:"Arxiv"})]}),Object(p.jsxs)("div",{children:[Object(p.jsx)("h4",{children:"Baseline Models"}),Object(p.jsx)("a",{href:"/",children:"Github"})]})]})]})})})})}}]),i}(n.Component),ce=se,re=function(e){Object(o.a)(i,e);var t=Object(l.a)(i);function i(){return Object(r.a)(this,i),t.apply(this,arguments)}return Object(a.a)(i,[{key:"render",value:function(){return Object(p.jsxs)("div",{className:"Ocl",children:[Object(p.jsx)(Z,{}),Object(p.jsx)($,{}),Object(p.jsx)(te,{}),Object(p.jsx)(ne,{}),Object(p.jsx)(ce,{}),Object(p.jsx)(_,{})]})}}]),i}(n.Component),ae=re,oe=function(e){Object(o.a)(i,e);var t=Object(l.a)(i);function i(){return Object(r.a)(this,i),t.apply(this,arguments)}return Object(a.a)(i,[{key:"render",value:function(){return Object(p.jsxs)("nav",{id:"nav-wrap",className:"opaque",children:[Object(p.jsx)("a",{className:"mobile-btn",href:"#nav-wrap",title:"Show navigation",children:"Show navigation"}),Object(p.jsx)("a",{className:"mobile-btn",href:"#home",title:"Hide navigation",children:"Hide navigation"}),Object(p.jsxs)("ul",{id:"nav",className:"nav",children:[Object(p.jsx)("li",{children:Object(p.jsx)("a",{className:"smoothscroll",href:"/",children:"Home"})}),Object(p.jsx)("li",{children:Object(p.jsx)("a",{className:"smoothscroll",href:"/#about",children:"About"})}),Object(p.jsx)("li",{children:Object(p.jsx)("a",{className:"smoothscroll",href:"/#news",children:"News"})}),Object(p.jsx)("li",{children:Object(p.jsx)("a",{className:"smoothscroll",href:"/#projects",children:"Projects"})}),Object(p.jsx)("li",{children:Object(p.jsx)("a",{className:"smoothscroll",href:"/#publications",children:"Publications"})}),Object(p.jsx)("li",{children:Object(p.jsx)("a",{className:"smoothscroll",href:"/#people",children:"People"})})]})]})}}]),i}(n.Component),le=oe,je=function(e){Object(o.a)(i,e);var t=Object(l.a)(i);function i(){return Object(r.a)(this,i),t.apply(this,arguments)}return Object(a.a)(i,[{key:"render",value:function(){return Object(p.jsxs)("div",{className:"Ocl",children:[Object(p.jsxs)("header",{id:"slim",children:[Object(p.jsx)(le,{}),Object(p.jsx)("div",{className:"nav-placeholder"}),Object(p.jsx)("div",{className:"row banner",children:Object(p.jsx)("div",{className:"banner-text",children:Object(p.jsxs)(d.Fade,{duration:1e3,children:[Object(p.jsx)("h1",{className:"responsive-headline",children:"name"}),Object(p.jsx)("h3",{children:"long title, may be your paper title"})]})})})]}),Object(p.jsxs)("div",{id:"resume",children:[Object(p.jsx)(d.Fade,{duration:1e3,children:Object(p.jsxs)("div",{className:"row work",children:[Object(p.jsx)("div",{className:"three columns header-col",children:Object(p.jsx)("h1",{children:Object(p.jsx)("span",{children:" About "})})}),Object(p.jsxs)("div",{className:"nine columns main-col date",children:[Object(p.jsx)("img",{alt:"put sth here",src:"/images/portfolio/2019_hake1.PNG"}),Object(p.jsx)("p",{children:"This is the description of our paper."})]})]})}),Object(p.jsx)(d.Slide,{left:!0,duration:1300,children:Object(p.jsxs)("div",{className:"row work",children:[Object(p.jsx)("div",{className:"three columns header-col",children:Object(p.jsx)("h1",{children:Object(p.jsx)("span",{children:" News "})})}),Object(p.jsx)("div",{className:"nine columns main-col date",children:Object(p.jsx)(w,{date:"1970.01.01",children:"Our paper is accepted"})})]})}),Object(p.jsx)(d.Slide,{left:!0,duration:1300,children:Object(p.jsxs)("div",{className:"row work",children:[Object(p.jsx)("div",{className:"three columns header-col",children:Object(p.jsx)("h1",{children:Object(p.jsx)("span",{children:"Resources"})})}),Object(p.jsxs)("div",{className:"nine columns main-col date",children:[Object(p.jsxs)("div",{children:[Object(p.jsx)("h4",{children:"Data"}),Object(p.jsx)("a",{href:"/",children:"Download link"}),Object(p.jsx)("a",{href:"/",children:"Licence"})]}),Object(p.jsxs)("div",{children:[Object(p.jsx)("h4",{children:"Paper"}),Object(p.jsx)("a",{href:"/",children:"Arxiv"})]}),Object(p.jsxs)("div",{children:[Object(p.jsx)("h4",{children:"Code and Models"}),Object(p.jsx)("a",{href:"/",children:"Github"})]})]})]})})]})," ",Object(p.jsx)(_,{})]})}}]),i}(n.Component),he=je,be=function(e){Object(o.a)(i,e);var t=Object(l.a)(i);function i(e){var n;return Object(r.a)(this,i),n=t.call(this,e),j.a.initialize("UA-110570651-1"),j.a.pageview(window.location.pathname),n}return Object(a.a)(i,[{key:"render",value:function(){return Object(p.jsx)(h.a,{children:Object(p.jsxs)(b.c,{children:[Object(p.jsx)(b.a,{path:"/",element:Object(p.jsx)(U,{})}),Object(p.jsx)(b.a,{path:"/ocl",element:Object(p.jsx)(ae,{})}),Object(p.jsx)(b.a,{path:"/hake",element:Object(p.jsx)(B,{})}),Object(p.jsx)(b.a,{path:"/pub/example",element:Object(p.jsx)(he,{})})]})})}}]),i}(n.Component),de=function(e){e&&e instanceof Function&&i.e(3).then(i.bind(null,49)).then((function(t){var i=t.getCLS,n=t.getFID,s=t.getFCP,c=t.getLCP,r=t.getTTFB;i(e),n(e),s(e),c(e),r(e)}))};c.a.render(Object(p.jsx)(be,{}),document.getElementById("root")),de()}},[[48,1,2]]]);
//# sourceMappingURL=main.17e754ee.chunk.js.map